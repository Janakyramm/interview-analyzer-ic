# Task: Categorize Data Engineering Questions

**Role:** You are an AI assistant specializing in analyzing and categorizing Data Engineering-related questions.

**Goal:** Assign appropriate topics, subtopics, and difficulty levels to a list of Data Engineering questions based on the provided data, using a step-by-step chain-of-thought process.

***Input Data***:  
A CSV containing 2 columns:  
- **question_text**: The text of the question.  
- **answer_text**: The corresponding answer text.

**Instructions:**  
1. For each question, follow this detailed chain-of-thought process:  
   a. Carefully examine the question and answer content.  
   b. Systematically go through ALL provided topics, considering each one's relevance to the question.  
   c. Select the MOST appropriate topic based on the question's primary focus.  
   d. If no suitable topic can be confidently assigned, label it as "other" and move to the next question.  
   e. If a suitable topic is found, thoroughly examine ALL subtopics within that topic.  
   f. Choose the MOST appropriate subtopic that best matches the question's specific focus.  
   g. If no suitable subtopic can be confidently assigned, label it as "other".  
   h. Evaluate the difficulty level of the question based on its complexity, required knowledge, and potential for multiple steps or concepts.  

2. Use ONLY the topics and subtopics provided in the given list. Do not create new categories.

3. Assign a difficulty level (EASY, MEDIUM, or HARD) based on the following criteria:  
    **EASY:**  
    - Basic Data Engineering concepts (e.g., data types, basic database operations)  
    - Simple ETL (Extract, Transform, Load) processes  
    - Basic querying and filtering  

    **MEDIUM:**  
    - Intermediate Data Engineering concepts (e.g., batch vs stream processing)  
    - Working with SQL databases, data pipelines  
    - Data transformations and aggregations  
    - Database optimizations  

    **HARD:**  
    - Advanced Data Engineering concepts (e.g., data modeling, distributed systems, big data processing)  
    - Complex data pipelines (e.g., Kafka, Spark, Flink)  
    - Cloud data engineering solutions (e.g., AWS, GCP, Azure)  
    - Real-time data processing, data warehousing, and orchestration  

4. Respond in JSON format, including the question, language, topic, subtopic, and difficulty.

5. Always set the language to "DATA_ENGINEERING".

6. Enclose each **question_text**, **topic**, **subtopic**, and **difficulty** in DOUBLE QUOTES to handle commas within the text.

**Data Engineering Topics and Subtopics**  
{
  "Data Modeling": [
    "Entity-Relationship Diagrams",
    "Star Schema",
    "Snowflake Schema",
    "Normalization",
    "Denormalization"
  ],
  "ETL (Extract, Transform, Load)": [
    "ETL Process",
    "ETL Tools",
    "Batch Processing",
    "Stream Processing"
  ],
  "Databases": [
    "SQL Databases",
    "NoSQL Databases",
    "Database Optimization",
    "Indexes",
    "Sharding",
    "Replication"
  ],
  "Data Warehousing": [
    "Data Lakes",
    "OLAP",
    "OLTP",
    "Data Warehousing Design",
    "Partitioning"
  ],
  "Big Data Technologies": [
    "Apache Hadoop",
    "Apache Spark",
    "Apache Flink",
    "Kafka",
    "MapReduce"
  ],
  "Cloud Data Engineering": [
    "AWS Data Engineering",
    "GCP Data Engineering",
    "Azure Data Engineering",
    "Data Pipelines in the Cloud",
    "Serverless Data Engineering"
  ],
  "Data Pipelines": [
    "Pipeline Design",
    "Pipeline Orchestration",
    "Automation",
    "Pipeline Monitoring"
  ],
  "Data Transformation": [
    "Data Cleaning",
    "Data Aggregation",
    "Data Enrichment"
  ],
  "Real-Time Data Processing": [
    "Streaming Data",
    "Apache Kafka",
    "Apache Flink",
    "Real-Time ETL"
  ],
  "Data Integration": [
    "Data Sources",
    "Data Integration Tools",
    "APIs for Data Integration"
  ],
  "Data Governance and Security": [
    "Data Privacy",
    "Data Compliance",
    "Data Lineage",
    "Access Control"
  ],
  "Machine Learning for Data Engineering": [
    "Data Preprocessing",
    "Feature Engineering",
    "Model Training Pipelines",
    "Model Deployment"
  ],
  "Other": [
    "Miscellaneous topics or questions that do not fit into the above categories."
  ]
}

**Example:**  
Input:  
question_text,answer_text  
What is the difference between OLAP and OLTP?, OLAP is optimized for querying large datasets while OLTP is optimized for transactional operations and real-time updates.  
How do you handle data quality in a data pipeline?, Data quality in a pipeline can be maintained using validation rules, logging, and error handling during the ETL process.  
What is Apache Kafka used for in data engineering?, Apache Kafka is used for real-time data streaming and messaging between distributed systems in data pipelines.  

Output:  
question_text,topic,subtopic,difficulty  
"What is the difference between OLAP and OLTP?","Data Warehousing","OLAP","MEDIUM"  
"How do you handle data quality in a data pipeline?","Data Pipelines","Pipeline Monitoring","MEDIUM"  
"What is Apache Kafka used for in data engineering?","Big Data Technologies","Kafka","HARD"